[
  {
    "objectID": "Homework5.html",
    "href": "Homework5.html",
    "title": "Homework 5 - Heart Disease Modeling",
    "section": "",
    "text": "What is the purpose of using cross-validation when fitting a random forest model?\n\n\nThe purpose of cross-validation is to ensure a prediction model chosen has a combination of parameters that provide the most accurate prediction without over-fitting to the training set.\n\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm is where the sample data set has bootstrapped samples taken from it, decision trees generated from each sample, then the average of the decision trees determined to develop the prediction model.\n\n\nWhat is meant by a general linear model?\n\n\nA general linear model is one where a variety of variable types can be analyzed on how well they predict a continuous variable of interest.\n\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\n\nAdding an interaction term allows us to identify if the slopes of each variable’s predictors are independent or if one affects the other. When they are not used in a prediction model, it is assumed that the outcome of one variable is independent from the other predictors in the model.\n\n\nWhy do we split our data into a training and test set?\n\n\nWe split data into a training and test set to ensure our model is not biased to the data set we’re using to develop the model. Otherwise we risk over-fitting to the data used to build the model, which will result in low accuracy of predicting how new data points will affect an outcome of interest.\n\n\n\n\nThe first thing we’ll need to do is establish the libraries required to run the code for each of the models we’re going to develop.\n\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(gbm)\nlibrary(rpart)\nlibrary(randomForest)\nlibrary(haven)\nlibrary(knitr)\nlibrary(tree)\nlibrary(rgl) \nlibrary(class)\n\n\n\n\n\nFirst we will read the data set into R, and call the data frame heart_df.\n\nheart_df &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/heart.csv\", \n                     show_col_types = FALSE)\n\nheart_df\n\n# A tibble: 918 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nNext we will check for NA values throughout heart_df.\n\nsum_na &lt;- function(col) {\n  sum(is.na(col))\n}\n\nheart_df_na_summary &lt;- heart_df |&gt;\n  summarize(across(everything(), sum_na))\n\nprint(heart_df_na_summary)\n\n# A tibble: 1 × 12\n    Age   Sex ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n  &lt;int&gt; &lt;int&gt;         &lt;int&gt;     &lt;int&gt;       &lt;int&gt;     &lt;int&gt;      &lt;int&gt; &lt;int&gt;\n1     0     0             0         0           0         0          0     0\n# ℹ 4 more variables: ExerciseAngina &lt;int&gt;, Oldpeak &lt;int&gt;, ST_Slope &lt;int&gt;,\n#   HeartDisease &lt;int&gt;\n\n\nWe see that there are no missing values in the data set.\nNext we will summarize the data frame to determine if there are any irregularities that need to be further investigated before generating our prediction models. Summarized graphs of the variables are being done with respect to HeartDisease in order to determine which ones will be suitable for prediction modeling.\n\nprint(summary(heart_df))\n\n      Age            Sex            ChestPainType        RestingBP    \n Min.   :28.00   Length:918         Length:918         Min.   :  0.0  \n 1st Qu.:47.00   Class :character   Class :character   1st Qu.:120.0  \n Median :54.00   Mode  :character   Mode  :character   Median :130.0  \n Mean   :53.51                                         Mean   :132.4  \n 3rd Qu.:60.00                                         3rd Qu.:140.0  \n Max.   :77.00                                         Max.   :200.0  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   :  0.0   Min.   :0.0000   Length:918         Min.   : 60.0  \n 1st Qu.:173.2   1st Qu.:0.0000   Class :character   1st Qu.:120.0  \n Median :223.0   Median :0.0000   Mode  :character   Median :138.0  \n Mean   :198.8   Mean   :0.2331                      Mean   :136.8  \n 3rd Qu.:267.0   3rd Qu.:0.0000                      3rd Qu.:156.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:918         Min.   :-2.6000   Length:918         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.6000   Mode  :character   Median :1.0000  \n                    Mean   : 0.8874                      Mean   :0.5534  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n\nReview of the numeric variable summaries shows that there is an irregularity in the RestingBP data and that an irrgeularity may also exist in the Cholesterol data. For the five character variables, we generated graphic summaries that will be used to determine if the variable data requires further investigation for data cleaning or not.\nThe irregularity in RestingBP is the summary information shows a minimum entry of 0.0. This value is highly unlikely unless the PT observed is already a corpse (or mannequin). First we will generate a histogram of the RestingBP values with regards to the HeartDisease’s values of “0” for “Normal” and “1” for “Heart Disease” to determine if the RestingBP value is an outlier, and how many other outliers may be present.\n\nggplot(heart_df, aes(RestingBP)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Resting BP by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(heart_df$RestingBP), sd = sd(heart_df$RestingBP))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nThe histograms shows that the “0” value in RestingBP is an outlier, and that it is the only one. The remaining RestingBP data models a fairly normal distribution. Because there is only one outlier, it would be reasonable to remove it or replace the value with the mean of the remaining RestingBP values. RestingBP is a suitable variable for prediciton modeling.\n\nadjusted_heart_df &lt;- heart_df |&gt;\n  filter(RestingBP != 0)\n\nadjusted_heart_df\n\n# A tibble: 917 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 907 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nHealthline reports that serum cholesterol levels are calculated by every person has some level of total cholesterol when tested for LDL, HDL, and Triglycerides. Because of this, the summary of Cholesterol showing a minimum entry of 0.0 is highly unlikely as mentioned above.Like with RestingBP, we will use a histogram to summarize the Cholesterol data\n\nggplot(adjusted_heart_df, aes(Cholesterol)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Cholesterol by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(heart_df$Cholesterol), \n                            sd = sd(heart_df$Cholesterol))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nThe histogram shows that there are a substantial amount of outliers with Cholesterol levels of “0” in both groups. The graphical summary also shows that there are outliers in range of 450 to 600 of both subgroups.\n\nchol_matrix &lt;- list(\"Cholesterol is Zero\" = summary(heart_df$Cholesterol == 0))\n\nprint(chol_matrix)\n\n$`Cholesterol is Zero`\n   Mode   FALSE    TRUE \nlogical     746     172 \n\n\nThe using “Cholesterol is zero” as our logic baseline, the summary() function determined that there are 172 entries with “0” reported for the PTs Cholesterol level. This accounts for approximately 19% of the overall data set, which is a large amount of the sample population. This use of “0” in this magnitude suggests it was intentional, and probably used instead of “NA” or some other coding to indicate a sample wasn’t taken.\nHowever, substituting the mean of the remaining 81% of the Cholesterol levels for these values without knowing their distribution across the five data sources risks heavily biasing our prediction modeling to favor one group over another. Further summary analysis is required for assessing what to do with these observations.\n\nggplot(adjusted_heart_df, aes(HeartDisease, Cholesterol)) +\n  geom_boxplot(aes(group = HeartDisease), fill = \"#CC0000\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title=\"Boxplot of Cholesterol by Heart Disease\")\n\n\n\n\n\n\n\n\nReview of the HeartDisease sub-group box and whisker plots shows that the Cholesterol values of “0” greatly affect the IQR of the “Heart Disease” subgroup while having minimal to no effect on the “Normal” subgroup. The Cholesterol values of “0” do not appear to have an affect on the median values of either subgroup as they both are near the overall group median of 223.\nThe information provided by the three summary observations taken with respect to HeartDisease indicate that replacing the Cholesterol variable’s values of “0” with the mean of the remaining Cholesterol values is reasonable after removing the outlying values that are greater than or equal to 450.\nFirst, we will create an adjsuted data frame that excludes the Cholesterol outliers that are greater than or equal to 450.\n\nadjusted_heart_df &lt;- heart_df |&gt;\n  filter(Cholesterol &lt;= 450)\n\nadjusted_heart_df\n\n# A tibble: 910 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 900 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nNext, we will use the na_if() function to swap our “0” entries with “NA”, then use the mean() function to replace the “NA” values with the mean of the remaining values. Then we will then use histogram plots to view the changes to the Cholestorol and Cholestorol with repsect to HeartDisease.\n\nadjusted_heart_df$Cholesterol &lt;- na_if(adjusted_heart_df$Cholesterol, 0)\n\nadjusted_heart_df$Cholesterol[is.na(adjusted_heart_df$Cholesterol)] &lt;- mean(adjusted_heart_df$Cholesterol, na.rm = TRUE)\n\n\nggplot(adjusted_heart_df, aes(Cholesterol)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Cholesterol by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Cholesterol), sd = sd(adjusted_heart_df$Cholesterol))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nReview of the histograms show that our Cholesterol data maintained a normal distribution with the adjusted data centered on the mean. Next we will compare summary information between the original data and the adjusted data.\n\nprint(list(\"Original Heart Disease Cholesterol Summary\" = summary(heart_df$Cholesterol)))\n\n$`Original Heart Disease Cholesterol Summary`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   173.2   223.0   198.8   267.0   603.0 \n\nprint(list(\"Adjusted Heart Disease Cholesterol Summary\" = summary(adjusted_heart_df$Cholesterol)))\n\n$`Adjusted Heart Disease Cholesterol Summary`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   85.0   214.0   241.7   241.7   265.8   417.0 \n\n\nReview of the two summary tables show that there were small changes in the median and Q3 information. There were substantial changes in the Min, Q1, Mean, and Max values. These changes were expected after the adjustments to the Min and Max values. Cholesterol is a suitable variable for prediction modeling.\nNow that we have investigated the variables that first showed signs of needing addressed, we are going to continue analysis of the remaining variables\nNext we summarized the effect of Age on HeartDisease.\n\nggplot(adjusted_heart_df, aes(Age)) +\n  geom_histogram(aes(y=..density..), binwidth=5, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Age by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Age), \n                                         sd = sd(adjusted_heart_df$Age))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nReview of the histogram plots show that there is a difference in the subgroups where the median Age for the “Heart Disease” category is higher. There are no prevalent outliers in either subgroup. Age appears to be a suitable variable for prediction modeling.\nNext we summarized the effect of Sex on HeartDisease using a bar plot.\n\nheart_df_by_sex &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, Sex) |&gt;\n  summarize(count = n()) \n\nggplot(heart_df_by_sex, aes(HeartDisease, count, fill=Sex)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Sex\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe bar plot shows that there are more males than females in both subgroups of Heart Disease, which indicates that the results of our prediction models will be heavily biased towards males. To better understand this bias, we generated a contingency table of HeartDisease vs Sex.\n\nlist(\"Heart Disease by Sex\" = table(adjusted_heart_df$HeartDisease, adjusted_heart_df$Sex))\n\n$`Heart Disease by Sex`\n   \n      F   M\n  0 141 266\n  1  50 453\n\n\nThe table confirms that there are more substantially more males in both HeartDisease groups than females. Using a scale factor of 50 PTs, males outnumber females in the study by a ratio of approximately 7:2. The table also shows that the odds of females having heart disease are approximately 1:3 while the odds of males having heart disease are approximately 9:5.\nAlthough the data is biased towards males, the female group accounts for 191 observations, which is approximately 21% of the data set. With this in mind, the female group observations should remain in the prediction model.\nNext, we summarized Chest Pain Type using a bar plot.\n\nheart_df_by_pain &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, ChestPainType) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_pain, aes(HeartDisease, count, fill=ChestPainType)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Chest Pain Type\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary shows that the majority of PTs with heart disease were not experiencing chest pain (ASY). The summary also shows that the majority of PTs without heart disease were experiencing chest pain of some sort. Comparing these observations, it is suggestive that not having chest pain is an indicator of having heart disease. ChestPainType does not appear to be a suitable variable for our prediciton models based on this logic.\nNext we summarized FastingBS with respect to HeartDisease.\n\nadj_heart_df_by_fastbs &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, FastingBS) |&gt;\n  summarize(count = n())\n\nggplot(adj_heart_df_by_fastbs, aes(HeartDisease, count, fill= FastingBS)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Fasting BS\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nReview of the summary shows that there is a larger number of PTs with fasting blood sugar levels above 120 mg/dl. There are also more PTs in the “Heart Disease” category of HeartDisease. Because of the population difference in HeartDisease, we will generate a contingent table to further analyze FastingBS and determine if it is suitable for remaining in the projection model.\n\nlist(\"Heart Disease by Fasting BS\" = table(adjusted_heart_df$HeartDisease, adjusted_heart_df$FastingBS))\n\n$`Heart Disease by Fasting BS`\n   \n      0   1\n  0 364  43\n  1 335 168\n\n\nUsing a scaling factor of 50, review of the table shows that the proportion of PTs in the “Normal” heart disease category with “FastingBS&gt;120” is approximately 1:7 while the proportion of PTs in the “Heart Disease” heart disease category with “FastingBS&gt;120” is approximately 3:7. This proportion increase suggests that FastingBS is suitable for prediction modeling.\nNext we generated a summary table for Resting ECG with respect to the HeartDisease subgroups.\n\nheart_df_by_ecg &lt;- heart_df |&gt;\n  group_by(HeartDisease, RestingECG) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_ecg, aes(HeartDisease, count, fill=RestingECG)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Heart Disease by Resting ECG\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary plot for Resting ECG shows that there were higher levels in each RestingECG category for PTs in the Heart Disease group vs the PTs in the Normal group. The distribution of the RestingECG categories stayed approximately the same, which is suggestive that the changes between the subgroups may be a result of there being more PTs with heart disease than those who are normal. We will generate a contingency table between HeartDisease and RestingECG to investigate this further.\n\nprint(list(\"Heart Disease by Resting ECG\" = table(heart_df$HeartDisease, heart_df$RestingECG)))\n\n$`Heart Disease by Resting ECG`\n   \n    LVH Normal  ST\n  0  82    267  61\n  1 106    285 117\n\n\nRecalling the HeartDisease information from our adjusted data frame summary table,\n\nsummary(adjusted_heart_df$HeartDisease)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5527  1.0000  1.0000 \n\n\nthe mean for HeartDisease is “0.5527”. This shows that there are more PTs with heart disease than not in the study. Looking at the contingency table between HeartDisease and RestingECG, we see that the majority of PTs in both categories reported “Normal”.\nDue to the split of “-Normal” data into separate categories, we will need to combine the “-Normal” observation data and assess if it is equal to or greater than the “Normal” observations in either subgroup of HeartDisease. We will do this using the information provided by the HeartDisease by RestingECG contingency table.\nAdding the LVH and ST RestingECG values together for the “Normal” heart disease category provided us with a “-Normal” value of 143 PTS. Using a scaling factor of 50, the proportion of “Normal” to “-Normal” is approximately 5:3. This proportion heavily favors the “Normal” RestingECG group.\nAdding the LVH and ST RestingECG values together for the “Heart Disease” heart disease category provided us with a “-Normal” value of 123 PTs. Using a scaling factor of 50, the proportion of “Normal” to “-Normal” is approximately 5:4. This proportion favors the “Normal” RestingECG group.\nWhile both HeartDisease subgroups are heavily influenced by “Normal” RestingECG observations, the change in proportions where the “Heart Disease” HeartDisese category is almost even with “Normal” suggests that RestingECG may be suitable for use in prediction modeling.\nNext we summarized MaxHR with respect to HeartDisease.\n\nggplot(adjusted_heart_df, aes(MaxHR)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Max Heart Rate by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$MaxHR), sd = sd(adjusted_heart_df$MaxHR))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nThe summary graphics with respect to HeartDisease show that MaxHR has a generally normal distribution. When observed with respect to HeartDisease, the distribution of the “Normal” category tended to be higher than the “Heart Disease” category. MaxHR appears to be suitable for use in prediction modeling.\nNext we summarized ExerciseAngina with respect to HeartDisease.\n\nheart_df_by_ex_angina &lt;- heart_df |&gt;\n  group_by(HeartDisease, ExerciseAngina) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_ex_angina, aes(HeartDisease, count, fill= ExerciseAngina)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Heart Disease by Exercise Angina\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary graph show a change in the proportions between the Normal and Heart Disease groups. The proportion of exercised induced chest pain reported shifted from approximately 1:7 reporting chest pain to approximately 3:2 reporting chest pain. This data suggests that ExerciseAngina is a good variable for use in training our prediction model.\nFinally, we summarized Oldpeak with respect to HeartDisease.\n\nggplot(adjusted_heart_df, aes(Oldpeak)) +\n  geom_histogram(aes(y=..density..), binwidth=.1, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Oldpeak by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Oldpeak), sd = sd(adjusted_heart_df$Oldpeak))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nHistograms shows an fairly uniform distribution with a disproportionate number of observations having an Old Peak value of “0”. However, unlike our Cholesterol variable, these values do not appear to be outleirs from the rest of the variable group. Generating a summary table of Oldpeak\n\nprint(list(\"Old Peak value is Zero\" = summary(adjusted_heart_df$Oldpeak == 0)))\n\n$`Old Peak value is Zero`\n   Mode   FALSE    TRUE \nlogical     546     364 \n\n\nshows that there are 364 occurrences of this value being selected, which accounts for approximately 40% of the data. This suggests that its use was intentional. Generating a box plot summary for the variable\n\nggplot(adjusted_heart_df, aes(HeartDisease, Oldpeak)) +\n  geom_boxplot(fill=\"#CC0000\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Box Plot of Oldpeak\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nconfirms that the “0” values are not outliers in the overall data set, and they establish the Q1 value. A box plot of Oldpeak with reference to HeartDisease\n\nggplot(adjusted_heart_df, aes(HeartDisease, Oldpeak)) +\n  geom_boxplot(fill=\"#CC0000\", aes(group = HeartDisease)) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Box Plot of Oldpeak by Heart Disease\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nshows that the value “0” heavily influences the IQR of the “Normal” heart disease category. The value “0” has much less effect on the IQR of the “Heart Disease” heart disease category. This suggests that Oldpeak is suitable for inclusion in prediction modeling.\nWe did not analyze ST_Slope because the variable is being dropped from the data set per the Homework5 instructions.\n\n\n\n\nadjusted_heart_df &lt;- adjusted_heart_df |&gt;\n  mutate(HeartDiseaseFct = factor(HeartDisease, levels = c(0, 1), labels = c(\"No\", \"Yes\")), .before = 11) |&gt;\n  select(Age:HeartDiseaseFct)\n\n\n\n\nSet up dummy variables for ExerciseAngina, ChestPainType, and RestingECG using dummyVars() and predict(). Then we will convert the resulting table into a data frame for use in our predictive models.\n\n# Create the dummy variables\ndummies &lt;- dummyVars(~ ., data = adjusted_heart_df)\n\n# Create the new data set. Is initially in a `list` format. \ndummy_df &lt;- predict(dummies, newdata = adjusted_heart_df)\n\n# Convert the list into a tibble for use\nmodeling_df &lt;- as_tibble((dummy_df))\n\n# Output the data frame\nprint(modeling_df)\n\n# A tibble: 910 × 19\n     Age  SexF  SexM ChestPainTypeASY ChestPainTypeATA ChestPainTypeNAP\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1    40     0     1                0                1                0\n 2    49     1     0                0                0                1\n 3    37     0     1                0                1                0\n 4    48     1     0                1                0                0\n 5    54     0     1                0                0                1\n 6    39     0     1                0                0                1\n 7    45     1     0                0                1                0\n 8    54     0     1                0                1                0\n 9    37     0     1                1                0                0\n10    48     1     0                0                1                0\n# ℹ 900 more rows\n# ℹ 13 more variables: ChestPainTypeTA &lt;dbl&gt;, RestingBP &lt;dbl&gt;,\n#   Cholesterol &lt;dbl&gt;, FastingBS &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, MaxHR &lt;dbl&gt;,\n#   ExerciseAnginaN &lt;dbl&gt;, ExerciseAnginaY &lt;dbl&gt;, Oldpeak &lt;dbl&gt;,\n#   HeartDiseaseFct.No &lt;dbl&gt;, HeartDiseaseFct.Yes &lt;dbl&gt;\n\n\n\n\n\n\nNow that we have a data frame with dummy variables for the variables with factor levels, we can split the data into training and test sets for use when developing our prediction models.\nWe previously identified that ChestPainType and RestingECG are not suitable for prediction modeling. Because of this, we will remove them then create our training our test subsets.\n\n# Remove ChestPainType, RestingECG, and HeartDisese.No from the data frame\n\n# HeartDisease.No is being removed because it is the inverse of the variable of\n# HeartDisease.Yes which we are using as the predicted variable. \n\nmodeling_df &lt;- modeling_df |&gt;\n  relocate(starts_with(\"Heart\")) |&gt;\n  select(-HeartDiseaseFct.No) \n  \nmodeling_df\n\n# A tibble: 910 × 18\n   HeartDiseaseFct.Yes   Age  SexF  SexM ChestPainTypeASY ChestPainTypeATA\n                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1                   0    40     0     1                0                1\n 2                   1    49     1     0                0                0\n 3                   0    37     0     1                0                1\n 4                   1    48     1     0                1                0\n 5                   0    54     0     1                0                0\n 6                   0    39     0     1                0                0\n 7                   0    45     1     0                0                1\n 8                   0    54     0     1                0                1\n 9                   1    37     0     1                1                0\n10                   0    48     1     0                0                1\n# ℹ 900 more rows\n# ℹ 12 more variables: ChestPainTypeNAP &lt;dbl&gt;, ChestPainTypeTA &lt;dbl&gt;,\n#   RestingBP &lt;dbl&gt;, Cholesterol &lt;dbl&gt;, FastingBS &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, MaxHR &lt;dbl&gt;,\n#   ExerciseAnginaN &lt;dbl&gt;, ExerciseAnginaY &lt;dbl&gt;, Oldpeak &lt;dbl&gt;\n\n\nOur Training and Test data set rows are\n\n# Use set.seed() to ensure the output is reproducible each time the program\n# is used. We will do this for each block of code where the data iterations\n# may change. \n\nset.seed(1) \n\n# Create the model index that will partition the data\nmodelingIndex &lt;- createDataPartition(modeling_df$HeartDiseaseFct.Yes, p = .75, list = FALSE)\n\n# Create the training set by giving it the index row values\nmodelingTrain &lt;- modeling_df[modelingIndex, ]\n\n# Create the test set by givign it the remaining rows\nmodelingTest &lt;- modeling_df[-modelingIndex, ]\n\n# Output the dimensions to ensure the data subsets populated correctly\nprint(list(\"Training Data\" = dim(modelingTrain), \"Testing Data\" = dim(modelingTest)))\n\n$`Training Data`\n[1] 683  18\n\n$`Testing Data`\n[1] 227  18\n\n\nNow that we have created our test and training sets, we will fit them to a knn prediction model.\n\n\n\n\n\nAll of the variables are numeric after creating the data frame with dummy variables for the levels of Sex, ExerciseAngina, and HeartDisease. We previously removed variables ChestPainType and RestingECG due to them not being good for predictive modeling. We are now ready to train and test our prediction models.\nWe will assign the target variable as HeartDisease.Yes, and convert it to a factor in both our training and test sets for use in comparison modeling.\n\nmodelingTrain$HeartDiseaseFct.Yes &lt;- factor(modelingTrain$HeartDiseaseFct.Yes)\n\nmodelingTest$HeartDiseaseFct.Yes &lt;- factor(modelingTest$HeartDiseaseFct.Yes)\n\n\n\n\nWe are using the train() function to generate our fit using the KNN method. Parameters we’re using are 10 fold cross-validation with the number of steps being 3 and tuneGrid set so that the considered values for k are “1” through “40”.\n\nset.seed(1) #ensures reproducibility \n\nknnFit &lt;- train(HeartDiseaseFct.Yes ~ ., \n                data = modelingTrain,\n                method = \"knn\",\n                preProcess = c(\"center\", \"scale\"), \n                trControl = trainControl(method = \"repeatedcv\",\n                                         number = 10, \n                                         repeats = 3),\n                tuneGrid = data.frame(k = 1:40))\n\nprint(knnFit)\n\nk-Nearest Neighbors \n\n683 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 614, 615, 615, 614, 615, 615, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   1  0.7452592  0.4864624\n   2  0.7442427  0.4859925\n   3  0.7964954  0.5897771\n   4  0.8037848  0.6030912\n   5  0.8140434  0.6246115\n   6  0.8105761  0.6175392\n   7  0.8174745  0.6309950\n   8  0.8155491  0.6272299\n   9  0.8194635  0.6353733\n  10  0.8135670  0.6231668\n  11  0.8169981  0.6304209\n  12  0.8135741  0.6231213\n  13  0.8126286  0.6208704\n  14  0.8107106  0.6165781\n  15  0.8136303  0.6223585\n  16  0.8150516  0.6248249\n  17  0.8146036  0.6240824\n  18  0.8136234  0.6225030\n  19  0.8150942  0.6252484\n  20  0.8131334  0.6211978\n  21  0.8156053  0.6261971\n  22  0.8136587  0.6225243\n  23  0.8121741  0.6188596\n  24  0.8107177  0.6157477\n  25  0.8072864  0.6090371\n  26  0.8072508  0.6088302\n  27  0.8077695  0.6098379\n  28  0.8053185  0.6043274\n  29  0.8077552  0.6092609\n  30  0.8028746  0.5992229\n  31  0.8072937  0.6076927\n  32  0.8058160  0.6048312\n  33  0.8067964  0.6067857\n  34  0.8043667  0.6018587\n  35  0.8063346  0.6055834\n  36  0.8029030  0.5989761\n  37  0.8029243  0.5980254\n  38  0.8029243  0.5979392\n  39  0.8038976  0.5997103\n  40  0.8024412  0.5966529\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 9.\n\n\nThe kNN model identified k = 9 as the most accurate parameter value with a prediction accuracy value of 81.95%.\n\n\n\nNow that we have a model, we will check how well it does using the confusionMatrix function to analyze it against the test set.\n\n# Generate model prediction against the test data set\nknn_pred &lt;- predict(knnFit, newdata = modelingTest)\n\n# Validate the accuracy of the prediction against the test data set \nknn_accuracy &lt;- confusionMatrix(knn_pred, modelingTest$HeartDiseaseFct.Yes)\n\n# Output results\nprint(knn_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0  88  22\n         1  17 100\n                                          \n               Accuracy : 0.8282          \n                 95% CI : (0.7727, 0.8749)\n    No Information Rate : 0.5374          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6556          \n                                          \n Mcnemar's Test P-Value : 0.5218          \n                                          \n            Sensitivity : 0.8381          \n            Specificity : 0.8197          \n         Pos Pred Value : 0.8000          \n         Neg Pred Value : 0.8547          \n             Prevalence : 0.4626          \n         Detection Rate : 0.3877          \n   Detection Prevalence : 0.4846          \n      Balanced Accuracy : 0.8289          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nconfusionMatrix testing showed that our kNN model is approximately 81.06% accurate at predicting if a PT has Heart Disease or not. This accuracy is higher than what our model accuracy generated during training.\n\n\n\n\n\n\nUsing the EDA from section 2.1 we are going to generate regression models using the adjacent categories probability, Bayesian general linear model, and general linear model types.\nFirst, we will need to create training and test sets without our dummy variables and rearrange the data frame to put variables we’re going to remove.\n\nadjusted_heart_df &lt;- adjusted_heart_df |&gt;\n  relocate(HeartDiseaseFct, .before = 1) |&gt;\n  relocate(ChestPainType, .after = Oldpeak) |&gt;\n  relocate(RestingECG, .after = Oldpeak)\n\nset.seed(1) #ensures reproducibility \n\n# Create the index to determine data split\nheart_index &lt;- createDataPartition(adjusted_heart_df$HeartDiseaseFct,\n                                 p = 0.75,\n                                 list = FALSE)\n\n# Create the train data set\nheart_train &lt;- adjusted_heart_df[heart_index, ]\n\n# Crete the test data set\nheart_test &lt;- adjusted_heart_df[-heart_index, ]\n\n# Output the dimensions to ensure the data subsets populated correctly\nprint(list(\"Heart Training Dimensions\" = dim(heart_train), \n           \"Heart Test Dimensions\" = dim(heart_test)))\n\n$`Heart Training Dimensions`\n[1] 684  11\n\n$`Heart Test Dimensions`\n[1] 226  11\n\n\nNow, we will fit the models on the training set using CV with the same parameters used in the kNN model.\nThe first model is based on using ExerciseAngina as a predictor variable. The second model is based on using Oldpeak as a predictor variable. The third model uses all variables in the data frame. ExerciseAngina and Oldpeak are chosen as independent predictors because of the differences between the subgroups of HeartDisease.\n\nset.seed(1) #ensures reproducibility \n\n# Predict using only ExerciseAngina\nmod1 &lt;- train(HeartDiseaseFct ~ ExerciseAngina, \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Predict using ExerciseAngina and Oldpeak\nmod2 &lt;- train(HeartDiseaseFct ~ ExerciseAngina + Oldpeak, \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Predict using all variables\nmod3 &lt;- train(HeartDiseaseFct ~ ., \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Create a data frame for use in side-by-side comparison of the results\nprint(data.frame(t(mod1$results), t(mod2$results), t(mod3$results)))\n\n                   X1       X1.1       X1.2\nparameter        none       none       none\nAccuracy    0.7324338  0.7626267  0.8148827\nKappa       0.4749257  0.5249901  0.6249328\nAccuracySD 0.05003336 0.05936164 0.05221871\nKappaSD    0.09532202  0.1175836  0.1056164\n\n\nThe best model of the three is model 3, the full model. ExerciseAngina tested well as an independent predictor with an accuracy rate of 73.24%. Adding Oldpeak only slightly improved the prediction model to an accuracy rate of 76.26% respectively, but were beaten out by the full model accurate rate of 81.77%.\nThe full model doing the best was not unexpected. There are several variables that appeared to influence HeartDisease. What was surprising is adding the remaining variables only increased the accuracy by “5.22%”.\nNow that we have chosen our model, we will check how well it does on the test set using the confusionMatrix function.\n\nset.seed(1) #ensures reproducibility \n\n# Generate model prediction against the test data set\nlr_pred &lt;- predict(mod3, newdata = heart_test)\n\n# Validate the accuracy of the prediction against the test data set\nlr_accuracy &lt;- confusionMatrix(lr_pred, heart_test$HeartDiseaseFct)\n\n# Output results\nprint(lr_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No   82  23\n       Yes  19 102\n                                          \n               Accuracy : 0.8142          \n                 95% CI : (0.7572, 0.8627)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6255          \n                                          \n Mcnemar's Test P-Value : 0.6434          \n                                          \n            Sensitivity : 0.8119          \n            Specificity : 0.8160          \n         Pos Pred Value : 0.7810          \n         Neg Pred Value : 0.8430          \n             Prevalence : 0.4469          \n         Detection Rate : 0.3628          \n   Detection Prevalence : 0.4646          \n      Balanced Accuracy : 0.8139          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nconfusionMatrix testing showed that our chosen logistic regression model is approximately 81.42% accurate at predicting if a PT has Heart Disease or not.\n\n\n\n\n\n\nThe variables chosen for the following models include the variables not tested previously Age, RestingBP, and MaxHR. These variables appeared to be suitable for predicting HeartDisease during EDA, but were not used in the LR modeling.\nFor consistency, we will be using the same train and test subsets used in performing our logistic regression models. With these subsets, we will generate a classification tree, random forest tree, and a boosted tree using repeated 10 fold CV along with specified parameters in order to select a best fit.\nFor our classification tree, we will be using method - “rpart” and tuning parameter “cp”. We will assign values “0” though “0.1” by “0.001” to “cp”.\n\nheart_train$HeartDiseaseFct &lt;- factor(heart_train$HeartDiseaseFct )\n\nheart_test$HeartDiseaseFct &lt;- factor(heart_test$HeartDiseaseFct)\n\n\nset.seed(1)\n\nrpart_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"rpart\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(cp = seq(0, 0.1, by = 0.001))\n                     )\n\nprint(rpart_train)\n\nCART \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  cp     Accuracy   Kappa    \n  0.000  0.6272165  0.2411720\n  0.001  0.6330563  0.2520685\n  0.002  0.6418159  0.2701780\n  0.003  0.6491049  0.2836107\n  0.004  0.6564152  0.2980856\n  0.005  0.6652387  0.3167001\n  0.006  0.6725916  0.3333849\n  0.007  0.6784740  0.3461025\n  0.008  0.6901108  0.3694299\n  0.009  0.6915601  0.3730399\n  0.010  0.6959292  0.3806008\n  0.011  0.6959506  0.3803255\n  0.012  0.6959506  0.3803255\n  0.013  0.6959506  0.3812563\n  0.014  0.6959506  0.3812563\n  0.015  0.6974211  0.3824056\n  0.016  0.6974211  0.3824056\n  0.017  0.7003623  0.3881406\n  0.018  0.7003623  0.3881406\n  0.019  0.6959506  0.3801877\n  0.020  0.6959506  0.3801877\n  0.021  0.6959506  0.3801877\n  0.022  0.6959506  0.3801877\n  0.023  0.6959506  0.3801877\n  0.024  0.6885976  0.3639843\n  0.025  0.6885976  0.3639843\n  0.026  0.6885976  0.3639843\n  0.027  0.6885976  0.3639843\n  0.028  0.6885976  0.3639843\n  0.029  0.6885976  0.3639843\n  0.030  0.6885976  0.3639843\n  0.031  0.6885976  0.3639843\n  0.032  0.6885976  0.3639843\n  0.033  0.6885976  0.3639843\n  0.034  0.6885976  0.3639843\n  0.035  0.6885976  0.3639843\n  0.036  0.6885976  0.3639843\n  0.037  0.6783035  0.3410922\n  0.038  0.6783035  0.3410922\n  0.039  0.6783035  0.3410922\n  0.040  0.6783035  0.3410922\n  0.041  0.6783035  0.3410922\n  0.042  0.6783035  0.3410922\n  0.043  0.6783035  0.3410922\n  0.044  0.6783035  0.3387667\n  0.045  0.6783035  0.3387667\n  0.046  0.6783035  0.3387667\n  0.047  0.6783035  0.3387667\n  0.048  0.6783035  0.3387667\n  0.049  0.6783035  0.3387667\n  0.050  0.6783035  0.3387667\n  0.051  0.6783035  0.3387667\n  0.052  0.6783035  0.3387667\n  0.053  0.6783035  0.3387667\n  0.054  0.6783035  0.3387667\n  0.055  0.6783035  0.3387667\n  0.056  0.6783035  0.3387667\n  0.057  0.6783035  0.3387667\n  0.058  0.6783035  0.3387667\n  0.059  0.6783035  0.3387667\n  0.060  0.6783035  0.3387667\n  0.061  0.6783035  0.3387667\n  0.062  0.6783035  0.3387667\n  0.063  0.6783035  0.3387667\n  0.064  0.6783035  0.3387667\n  0.065  0.6783035  0.3387667\n  0.066  0.6783035  0.3387667\n  0.067  0.6783035  0.3387667\n  0.068  0.6783035  0.3387667\n  0.069  0.6783035  0.3387667\n  0.070  0.6783035  0.3387667\n  0.071  0.6783035  0.3387667\n  0.072  0.6783035  0.3387667\n  0.073  0.6783035  0.3387667\n  0.074  0.6783035  0.3387667\n  0.075  0.6783035  0.3387667\n  0.076  0.6783035  0.3387667\n  0.077  0.6783035  0.3387667\n  0.078  0.6783035  0.3387667\n  0.079  0.6783035  0.3387667\n  0.080  0.6783035  0.3387667\n  0.081  0.6783035  0.3387667\n  0.082  0.6783035  0.3387667\n  0.083  0.6783035  0.3387667\n  0.084  0.6637042  0.3155123\n  0.085  0.6637042  0.3155123\n  0.086  0.6637042  0.3155123\n  0.087  0.6637042  0.3155123\n  0.088  0.6637042  0.3155123\n  0.089  0.6637042  0.3155123\n  0.090  0.6637042  0.3155123\n  0.091  0.6534314  0.3017520\n  0.092  0.6534314  0.3017520\n  0.093  0.6534314  0.3017520\n  0.094  0.6534314  0.3017520\n  0.095  0.6446078  0.2869951\n  0.096  0.6446078  0.2869951\n  0.097  0.6446078  0.2869951\n  0.098  0.6446078  0.2869951\n  0.099  0.6446078  0.2869951\n  0.100  0.6446078  0.2869951\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.018.\n\n\nThe optimal model using “rpart” had a cp = 0.03 with a prediction accuracy of 65.50%\nFor our random forest tree model, we will be using method = “rf” with mtry as the tuning parameter with the number of predictors for it’s value.\n\nset.seed(1)\n\nrf_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"rf\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(mtry = c(1, 2, 3))\n                     )\n\nprint(rf_train)\n\nRandom Forest \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  1     0.6651321  0.3192079\n  2     0.6401748  0.2702785\n  3     0.6285166  0.2471447\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 1.\n\n\nThe optimal model using “rf” was mtry = 1 with a prediction accuracy of 66.68%\nFor our boosted tree model, we will be using method = “gbm” with n.trees, interaction.depth, shrinkage, and n.minobsinnode.\n\nset.seed(1)\n\ngbm_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"gbm\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     verbose = FALSE, \n                     tuneGrid = expand.grid(n.trees = c(25, 50, 100, 200),\n                       interaction.depth = c(1, 2, 3), \n                       shrinkage = 0.1,\n                       n.minobsinnode = 10\n                       )\n                     )\n\nprint(gbm_train)\n\nStochastic Gradient Boosting \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  interaction.depth  n.trees  Accuracy   Kappa    \n  1                   25      0.6945013  0.3758984\n  1                   50      0.6974851  0.3823038\n  1                  100      0.6959506  0.3806259\n  1                  200      0.6901748  0.3688129\n  2                   25      0.6886189  0.3642760\n  2                   50      0.6900682  0.3671151\n  2                  100      0.6842072  0.3549362\n  2                  200      0.6840793  0.3580468\n  3                   25      0.7046462  0.3987894\n  3                   50      0.6959079  0.3809876\n  3                  100      0.6841006  0.3554644\n  3                  200      0.6739770  0.3359869\n\nTuning parameter 'shrinkage' was held constant at a value of 0.1\n\nTuning parameter 'n.minobsinnode' was held constant at a value of 10\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were n.trees = 25, interaction.depth =\n 3, shrinkage = 0.1 and n.minobsinnode = 10.\n\n\nThe optimal model using “gbm” was the combination of n.trees = 25, interaction.depth = 3, shrinkage = 0.1, and n.minobsinnode = 10 with a prediction accuracy of 70.48%\nCheck how each of the above chosen models do on the test set using the confusionMatrix function.\n\nset.seed(1)\n\n# Generate model predictions against the test data set\nrpart_train_pred &lt;- predict(rpart_train, newdata = heart_test)\n#rf_train_pred &lt;- predict(rf_train, newdata = heart_test)\n#gbm_train_pred &lt;- predict(boosted_train, newdata = heart_test)\n\n\n# Validate the accuracy of the prediction against the test data set\nrpart_accuracy &lt;- confusionMatrix(rpart_train_pred, heart_test$HeartDiseaseFct)\n#rf_accuracy &lt;- confusionMatrix(rf_train_pred, heart_test$HeartDiseaseFct)\n#gbm_accuracy &lt;- confusionMatrix(gbm_train_pred, heart_test$HeartDiseaseFct)\n\n\n# Frame the results for comparison\n#regTrees &lt;- data.frame(rpart_accuracy$overall, rf_accuracy$overall, boosted_accuracy$overall)\n\n# Output the results\n#print(regTrees)\n\nprint(rpart_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No   64  23\n       Yes  37 102\n                                          \n               Accuracy : 0.7345          \n                 95% CI : (0.6719, 0.7909)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : 1.403e-08       \n                                          \n                  Kappa : 0.4557          \n                                          \n Mcnemar's Test P-Value : 0.09329         \n                                          \n            Sensitivity : 0.6337          \n            Specificity : 0.8160          \n         Pos Pred Value : 0.7356          \n         Neg Pred Value : 0.7338          \n             Prevalence : 0.4469          \n         Detection Rate : 0.2832          \n   Detection Prevalence : 0.3850          \n      Balanced Accuracy : 0.7248          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nComparing our three regression tree models after processing them through the confusionMatrix function shows that the rpart regression tree method had the highest level of accuracy at 73.45%, closely followed by the “gbm” regression tree method with an accuracy level of 71.68%.\n\n\n\n\n\n\nWhen doing a side by side comparison of the confusionMatrix generated accuracy rates of the three selected model types,\n\nmodel &lt;- c(\"kNN\", \"LogRegression\", \"Tree\")\n\naccuracy &lt;- c(0.8282, 0.8142, 0.7345)\n\ncomparison &lt;- data.frame(model, accuracy)\n\nprint(list(\"Comparison of Prediction Models\" = comparison))\n\n$`Comparison of Prediction Models`\n          model accuracy\n1           kNN   0.8282\n2 LogRegression   0.8142\n3          Tree   0.7345\n\n\nwe found that the k-Nearest Neighbors model was the most accurate, closely followed by the Logistic Regression model. However, the tree models were not tested using the same variables as the kNN and Logistic Regression models. A true comparison of the models would require our selected tree model to train and test on every variable for prediction like the other models.\n\nset.seed(1) #ensures reproducibility \n\nrpart_train2 &lt;- train(HeartDiseaseFct ~ ., \n                     data = heart_train, \n                     method = \"rpart\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(cp = seq(0, 0.1, by = 0.001))\n                     )\n\nrpart_train_pred2 &lt;- predict(rpart_train2, newdata = heart_test)\n\nrpart_accuracy2 &lt;- confusionMatrix(rpart_train_pred2, heart_test$HeartDiseaseFct)\n\nprint(rpart_accuracy2)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  84  26\n       Yes 17  99\n                                          \n               Accuracy : 0.8097          \n                 95% CI : (0.7524, 0.8587)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : 4.247e-16       \n                                          \n                  Kappa : 0.6184          \n                                          \n Mcnemar's Test P-Value : 0.2225          \n                                          \n            Sensitivity : 0.8317          \n            Specificity : 0.7920          \n         Pos Pred Value : 0.7636          \n         Neg Pred Value : 0.8534          \n             Prevalence : 0.4469          \n         Detection Rate : 0.3717          \n   Detection Prevalence : 0.4867          \n      Balanced Accuracy : 0.8118          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nThe new matrix for comparison of model accuracy shows\n\nmodel &lt;- c(\"kNN\", \"LogRegression\", \"Tree\")\n\naccuracy &lt;- c(0.8282, 0.8142, 0.8097)\n\ncomparison &lt;- data.frame(model, accuracy)\n\nprint(list(\"Comparison of Prediction Models\" = comparison))\n\n$`Comparison of Prediction Models`\n          model accuracy\n1           kNN   0.8282\n2 LogRegression   0.8142\n3          Tree   0.8097\n\n\nthat there is no change in the accuracy rankings, but the Tree model’s accuracy had vastly improved by including the variables that were previously omitted."
  },
  {
    "objectID": "Homework5.html#task-1-conceptual-questions",
    "href": "Homework5.html#task-1-conceptual-questions",
    "title": "Homework 5 - Heart Disease Modeling",
    "section": "",
    "text": "What is the purpose of using cross-validation when fitting a random forest model?\n\n\nThe purpose of cross-validation is to ensure a prediction model chosen has a combination of parameters that provide the most accurate prediction without over-fitting to the training set.\n\n\nDescribe the bagged tree algorithm.\n\n\nThe bagged tree algorithm is where the sample data set has bootstrapped samples taken from it, decision trees generated from each sample, then the average of the decision trees determined to develop the prediction model.\n\n\nWhat is meant by a general linear model?\n\n\nA general linear model is one where a variety of variable types can be analyzed on how well they predict a continuous variable of interest.\n\n\nWhen fitting a multiple linear regression model, what does adding an interaction term do? That is, what does it allow the model to do differently as compared to when it is not included in the model?\n\n\nAdding an interaction term allows us to identify if the slopes of each variable’s predictors are independent or if one affects the other. When they are not used in a prediction model, it is assumed that the outcome of one variable is independent from the other predictors in the model.\n\n\nWhy do we split our data into a training and test set?\n\n\nWe split data into a training and test set to ensure our model is not biased to the data set we’re using to develop the model. Otherwise we risk over-fitting to the data used to build the model, which will result in low accuracy of predicting how new data points will affect an outcome of interest."
  },
  {
    "objectID": "Homework5.html#task-2-fitting-models",
    "href": "Homework5.html#task-2-fitting-models",
    "title": "Homework 5 - Heart Disease Modeling",
    "section": "",
    "text": "The first thing we’ll need to do is establish the libraries required to run the code for each of the models we’re going to develop.\n\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(gbm)\nlibrary(rpart)\nlibrary(randomForest)\nlibrary(haven)\nlibrary(knitr)\nlibrary(tree)\nlibrary(rgl) \nlibrary(class)\n\n\n\n\n\nFirst we will read the data set into R, and call the data frame heart_df.\n\nheart_df &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/heart.csv\", \n                     show_col_types = FALSE)\n\nheart_df\n\n# A tibble: 918 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 908 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nNext we will check for NA values throughout heart_df.\n\nsum_na &lt;- function(col) {\n  sum(is.na(col))\n}\n\nheart_df_na_summary &lt;- heart_df |&gt;\n  summarize(across(everything(), sum_na))\n\nprint(heart_df_na_summary)\n\n# A tibble: 1 × 12\n    Age   Sex ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n  &lt;int&gt; &lt;int&gt;         &lt;int&gt;     &lt;int&gt;       &lt;int&gt;     &lt;int&gt;      &lt;int&gt; &lt;int&gt;\n1     0     0             0         0           0         0          0     0\n# ℹ 4 more variables: ExerciseAngina &lt;int&gt;, Oldpeak &lt;int&gt;, ST_Slope &lt;int&gt;,\n#   HeartDisease &lt;int&gt;\n\n\nWe see that there are no missing values in the data set.\nNext we will summarize the data frame to determine if there are any irregularities that need to be further investigated before generating our prediction models. Summarized graphs of the variables are being done with respect to HeartDisease in order to determine which ones will be suitable for prediction modeling.\n\nprint(summary(heart_df))\n\n      Age            Sex            ChestPainType        RestingBP    \n Min.   :28.00   Length:918         Length:918         Min.   :  0.0  \n 1st Qu.:47.00   Class :character   Class :character   1st Qu.:120.0  \n Median :54.00   Mode  :character   Mode  :character   Median :130.0  \n Mean   :53.51                                         Mean   :132.4  \n 3rd Qu.:60.00                                         3rd Qu.:140.0  \n Max.   :77.00                                         Max.   :200.0  \n  Cholesterol      FastingBS       RestingECG            MaxHR      \n Min.   :  0.0   Min.   :0.0000   Length:918         Min.   : 60.0  \n 1st Qu.:173.2   1st Qu.:0.0000   Class :character   1st Qu.:120.0  \n Median :223.0   Median :0.0000   Mode  :character   Median :138.0  \n Mean   :198.8   Mean   :0.2331                      Mean   :136.8  \n 3rd Qu.:267.0   3rd Qu.:0.0000                      3rd Qu.:156.0  \n Max.   :603.0   Max.   :1.0000                      Max.   :202.0  \n ExerciseAngina        Oldpeak          ST_Slope          HeartDisease   \n Length:918         Min.   :-2.6000   Length:918         Min.   :0.0000  \n Class :character   1st Qu.: 0.0000   Class :character   1st Qu.:0.0000  \n Mode  :character   Median : 0.6000   Mode  :character   Median :1.0000  \n                    Mean   : 0.8874                      Mean   :0.5534  \n                    3rd Qu.: 1.5000                      3rd Qu.:1.0000  \n                    Max.   : 6.2000                      Max.   :1.0000  \n\n\nReview of the numeric variable summaries shows that there is an irregularity in the RestingBP data and that an irrgeularity may also exist in the Cholesterol data. For the five character variables, we generated graphic summaries that will be used to determine if the variable data requires further investigation for data cleaning or not.\nThe irregularity in RestingBP is the summary information shows a minimum entry of 0.0. This value is highly unlikely unless the PT observed is already a corpse (or mannequin). First we will generate a histogram of the RestingBP values with regards to the HeartDisease’s values of “0” for “Normal” and “1” for “Heart Disease” to determine if the RestingBP value is an outlier, and how many other outliers may be present.\n\nggplot(heart_df, aes(RestingBP)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Resting BP by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(heart_df$RestingBP), sd = sd(heart_df$RestingBP))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nThe histograms shows that the “0” value in RestingBP is an outlier, and that it is the only one. The remaining RestingBP data models a fairly normal distribution. Because there is only one outlier, it would be reasonable to remove it or replace the value with the mean of the remaining RestingBP values. RestingBP is a suitable variable for prediciton modeling.\n\nadjusted_heart_df &lt;- heart_df |&gt;\n  filter(RestingBP != 0)\n\nadjusted_heart_df\n\n# A tibble: 917 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 907 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nHealthline reports that serum cholesterol levels are calculated by every person has some level of total cholesterol when tested for LDL, HDL, and Triglycerides. Because of this, the summary of Cholesterol showing a minimum entry of 0.0 is highly unlikely as mentioned above.Like with RestingBP, we will use a histogram to summarize the Cholesterol data\n\nggplot(adjusted_heart_df, aes(Cholesterol)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Cholesterol by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(heart_df$Cholesterol), \n                            sd = sd(heart_df$Cholesterol))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nThe histogram shows that there are a substantial amount of outliers with Cholesterol levels of “0” in both groups. The graphical summary also shows that there are outliers in range of 450 to 600 of both subgroups.\n\nchol_matrix &lt;- list(\"Cholesterol is Zero\" = summary(heart_df$Cholesterol == 0))\n\nprint(chol_matrix)\n\n$`Cholesterol is Zero`\n   Mode   FALSE    TRUE \nlogical     746     172 \n\n\nThe using “Cholesterol is zero” as our logic baseline, the summary() function determined that there are 172 entries with “0” reported for the PTs Cholesterol level. This accounts for approximately 19% of the overall data set, which is a large amount of the sample population. This use of “0” in this magnitude suggests it was intentional, and probably used instead of “NA” or some other coding to indicate a sample wasn’t taken.\nHowever, substituting the mean of the remaining 81% of the Cholesterol levels for these values without knowing their distribution across the five data sources risks heavily biasing our prediction modeling to favor one group over another. Further summary analysis is required for assessing what to do with these observations.\n\nggplot(adjusted_heart_df, aes(HeartDisease, Cholesterol)) +\n  geom_boxplot(aes(group = HeartDisease), fill = \"#CC0000\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title=\"Boxplot of Cholesterol by Heart Disease\")\n\n\n\n\n\n\n\n\nReview of the HeartDisease sub-group box and whisker plots shows that the Cholesterol values of “0” greatly affect the IQR of the “Heart Disease” subgroup while having minimal to no effect on the “Normal” subgroup. The Cholesterol values of “0” do not appear to have an affect on the median values of either subgroup as they both are near the overall group median of 223.\nThe information provided by the three summary observations taken with respect to HeartDisease indicate that replacing the Cholesterol variable’s values of “0” with the mean of the remaining Cholesterol values is reasonable after removing the outlying values that are greater than or equal to 450.\nFirst, we will create an adjsuted data frame that excludes the Cholesterol outliers that are greater than or equal to 450.\n\nadjusted_heart_df &lt;- heart_df |&gt;\n  filter(Cholesterol &lt;= 450)\n\nadjusted_heart_df\n\n# A tibble: 910 × 12\n     Age Sex   ChestPainType RestingBP Cholesterol FastingBS RestingECG MaxHR\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1    40 M     ATA                 140         289         0 Normal       172\n 2    49 F     NAP                 160         180         0 Normal       156\n 3    37 M     ATA                 130         283         0 ST            98\n 4    48 F     ASY                 138         214         0 Normal       108\n 5    54 M     NAP                 150         195         0 Normal       122\n 6    39 M     NAP                 120         339         0 Normal       170\n 7    45 F     ATA                 130         237         0 Normal       170\n 8    54 M     ATA                 110         208         0 Normal       142\n 9    37 M     ASY                 140         207         0 Normal       130\n10    48 F     ATA                 120         284         0 Normal       120\n# ℹ 900 more rows\n# ℹ 4 more variables: ExerciseAngina &lt;chr&gt;, Oldpeak &lt;dbl&gt;, ST_Slope &lt;chr&gt;,\n#   HeartDisease &lt;dbl&gt;\n\n\nNext, we will use the na_if() function to swap our “0” entries with “NA”, then use the mean() function to replace the “NA” values with the mean of the remaining values. Then we will then use histogram plots to view the changes to the Cholestorol and Cholestorol with repsect to HeartDisease.\n\nadjusted_heart_df$Cholesterol &lt;- na_if(adjusted_heart_df$Cholesterol, 0)\n\nadjusted_heart_df$Cholesterol[is.na(adjusted_heart_df$Cholesterol)] &lt;- mean(adjusted_heart_df$Cholesterol, na.rm = TRUE)\n\n\nggplot(adjusted_heart_df, aes(Cholesterol)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Cholesterol by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Cholesterol), sd = sd(adjusted_heart_df$Cholesterol))) +\n  facet_wrap(~HeartDisease)\n\n\n\n\n\n\n\n\nReview of the histograms show that our Cholesterol data maintained a normal distribution with the adjusted data centered on the mean. Next we will compare summary information between the original data and the adjusted data.\n\nprint(list(\"Original Heart Disease Cholesterol Summary\" = summary(heart_df$Cholesterol)))\n\n$`Original Heart Disease Cholesterol Summary`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   173.2   223.0   198.8   267.0   603.0 \n\nprint(list(\"Adjusted Heart Disease Cholesterol Summary\" = summary(adjusted_heart_df$Cholesterol)))\n\n$`Adjusted Heart Disease Cholesterol Summary`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   85.0   214.0   241.7   241.7   265.8   417.0 \n\n\nReview of the two summary tables show that there were small changes in the median and Q3 information. There were substantial changes in the Min, Q1, Mean, and Max values. These changes were expected after the adjustments to the Min and Max values. Cholesterol is a suitable variable for prediction modeling.\nNow that we have investigated the variables that first showed signs of needing addressed, we are going to continue analysis of the remaining variables\nNext we summarized the effect of Age on HeartDisease.\n\nggplot(adjusted_heart_df, aes(Age)) +\n  geom_histogram(aes(y=..density..), binwidth=5, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Age by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Age), \n                                         sd = sd(adjusted_heart_df$Age))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nReview of the histogram plots show that there is a difference in the subgroups where the median Age for the “Heart Disease” category is higher. There are no prevalent outliers in either subgroup. Age appears to be a suitable variable for prediction modeling.\nNext we summarized the effect of Sex on HeartDisease using a bar plot.\n\nheart_df_by_sex &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, Sex) |&gt;\n  summarize(count = n()) \n\nggplot(heart_df_by_sex, aes(HeartDisease, count, fill=Sex)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Sex\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe bar plot shows that there are more males than females in both subgroups of Heart Disease, which indicates that the results of our prediction models will be heavily biased towards males. To better understand this bias, we generated a contingency table of HeartDisease vs Sex.\n\nlist(\"Heart Disease by Sex\" = table(adjusted_heart_df$HeartDisease, adjusted_heart_df$Sex))\n\n$`Heart Disease by Sex`\n   \n      F   M\n  0 141 266\n  1  50 453\n\n\nThe table confirms that there are more substantially more males in both HeartDisease groups than females. Using a scale factor of 50 PTs, males outnumber females in the study by a ratio of approximately 7:2. The table also shows that the odds of females having heart disease are approximately 1:3 while the odds of males having heart disease are approximately 9:5.\nAlthough the data is biased towards males, the female group accounts for 191 observations, which is approximately 21% of the data set. With this in mind, the female group observations should remain in the prediction model.\nNext, we summarized Chest Pain Type using a bar plot.\n\nheart_df_by_pain &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, ChestPainType) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_pain, aes(HeartDisease, count, fill=ChestPainType)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Chest Pain Type\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary shows that the majority of PTs with heart disease were not experiencing chest pain (ASY). The summary also shows that the majority of PTs without heart disease were experiencing chest pain of some sort. Comparing these observations, it is suggestive that not having chest pain is an indicator of having heart disease. ChestPainType does not appear to be a suitable variable for our prediciton models based on this logic.\nNext we summarized FastingBS with respect to HeartDisease.\n\nadj_heart_df_by_fastbs &lt;- adjusted_heart_df |&gt;\n  group_by(HeartDisease, FastingBS) |&gt;\n  summarize(count = n())\n\nggplot(adj_heart_df_by_fastbs, aes(HeartDisease, count, fill= FastingBS)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Bar Plot of Heart Disease by Fasting BS\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nReview of the summary shows that there is a larger number of PTs with fasting blood sugar levels above 120 mg/dl. There are also more PTs in the “Heart Disease” category of HeartDisease. Because of the population difference in HeartDisease, we will generate a contingent table to further analyze FastingBS and determine if it is suitable for remaining in the projection model.\n\nlist(\"Heart Disease by Fasting BS\" = table(adjusted_heart_df$HeartDisease, adjusted_heart_df$FastingBS))\n\n$`Heart Disease by Fasting BS`\n   \n      0   1\n  0 364  43\n  1 335 168\n\n\nUsing a scaling factor of 50, review of the table shows that the proportion of PTs in the “Normal” heart disease category with “FastingBS&gt;120” is approximately 1:7 while the proportion of PTs in the “Heart Disease” heart disease category with “FastingBS&gt;120” is approximately 3:7. This proportion increase suggests that FastingBS is suitable for prediction modeling.\nNext we generated a summary table for Resting ECG with respect to the HeartDisease subgroups.\n\nheart_df_by_ecg &lt;- heart_df |&gt;\n  group_by(HeartDisease, RestingECG) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_ecg, aes(HeartDisease, count, fill=RestingECG)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Heart Disease by Resting ECG\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary plot for Resting ECG shows that there were higher levels in each RestingECG category for PTs in the Heart Disease group vs the PTs in the Normal group. The distribution of the RestingECG categories stayed approximately the same, which is suggestive that the changes between the subgroups may be a result of there being more PTs with heart disease than those who are normal. We will generate a contingency table between HeartDisease and RestingECG to investigate this further.\n\nprint(list(\"Heart Disease by Resting ECG\" = table(heart_df$HeartDisease, heart_df$RestingECG)))\n\n$`Heart Disease by Resting ECG`\n   \n    LVH Normal  ST\n  0  82    267  61\n  1 106    285 117\n\n\nRecalling the HeartDisease information from our adjusted data frame summary table,\n\nsummary(adjusted_heart_df$HeartDisease)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5527  1.0000  1.0000 \n\n\nthe mean for HeartDisease is “0.5527”. This shows that there are more PTs with heart disease than not in the study. Looking at the contingency table between HeartDisease and RestingECG, we see that the majority of PTs in both categories reported “Normal”.\nDue to the split of “-Normal” data into separate categories, we will need to combine the “-Normal” observation data and assess if it is equal to or greater than the “Normal” observations in either subgroup of HeartDisease. We will do this using the information provided by the HeartDisease by RestingECG contingency table.\nAdding the LVH and ST RestingECG values together for the “Normal” heart disease category provided us with a “-Normal” value of 143 PTS. Using a scaling factor of 50, the proportion of “Normal” to “-Normal” is approximately 5:3. This proportion heavily favors the “Normal” RestingECG group.\nAdding the LVH and ST RestingECG values together for the “Heart Disease” heart disease category provided us with a “-Normal” value of 123 PTs. Using a scaling factor of 50, the proportion of “Normal” to “-Normal” is approximately 5:4. This proportion favors the “Normal” RestingECG group.\nWhile both HeartDisease subgroups are heavily influenced by “Normal” RestingECG observations, the change in proportions where the “Heart Disease” HeartDisese category is almost even with “Normal” suggests that RestingECG may be suitable for use in prediction modeling.\nNext we summarized MaxHR with respect to HeartDisease.\n\nggplot(adjusted_heart_df, aes(MaxHR)) +\n  geom_histogram(aes(y=..density..), binwidth=10, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Max Heart Rate by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$MaxHR), sd = sd(adjusted_heart_df$MaxHR))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nThe summary graphics with respect to HeartDisease show that MaxHR has a generally normal distribution. When observed with respect to HeartDisease, the distribution of the “Normal” category tended to be higher than the “Heart Disease” category. MaxHR appears to be suitable for use in prediction modeling.\nNext we summarized ExerciseAngina with respect to HeartDisease.\n\nheart_df_by_ex_angina &lt;- heart_df |&gt;\n  group_by(HeartDisease, ExerciseAngina) |&gt;\n  summarize(count = n())\n\nggplot(heart_df_by_ex_angina, aes(HeartDisease, count, fill= ExerciseAngina)) +\n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Heart Disease by Exercise Angina\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nThe summary graph show a change in the proportions between the Normal and Heart Disease groups. The proportion of exercised induced chest pain reported shifted from approximately 1:7 reporting chest pain to approximately 3:2 reporting chest pain. This data suggests that ExerciseAngina is a good variable for use in training our prediction model.\nFinally, we summarized Oldpeak with respect to HeartDisease.\n\nggplot(adjusted_heart_df, aes(Oldpeak)) +\n  geom_histogram(aes(y=..density..), binwidth=.1, fill=\"#CC0000\", color = \"lightgray\") +\n  labs(title=\"Histogram of Oldpeak by Heart Disease\", y=\"Density (# of PTs)\") +\n  stat_function(fun = dnorm, args = list(mean = mean(adjusted_heart_df$Oldpeak), sd = sd(adjusted_heart_df$Oldpeak))) +\n  facet_grid(~HeartDisease)\n\n\n\n\n\n\n\n\nHistograms shows an fairly uniform distribution with a disproportionate number of observations having an Old Peak value of “0”. However, unlike our Cholesterol variable, these values do not appear to be outleirs from the rest of the variable group. Generating a summary table of Oldpeak\n\nprint(list(\"Old Peak value is Zero\" = summary(adjusted_heart_df$Oldpeak == 0)))\n\n$`Old Peak value is Zero`\n   Mode   FALSE    TRUE \nlogical     546     364 \n\n\nshows that there are 364 occurrences of this value being selected, which accounts for approximately 40% of the data. This suggests that its use was intentional. Generating a box plot summary for the variable\n\nggplot(adjusted_heart_df, aes(HeartDisease, Oldpeak)) +\n  geom_boxplot(fill=\"#CC0000\") +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Box Plot of Oldpeak\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nconfirms that the “0” values are not outliers in the overall data set, and they establish the Q1 value. A box plot of Oldpeak with reference to HeartDisease\n\nggplot(adjusted_heart_df, aes(HeartDisease, Oldpeak)) +\n  geom_boxplot(fill=\"#CC0000\", aes(group = HeartDisease)) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  labs(title = \"Box Plot of Oldpeak by Heart Disease\", y=\"# of PTs\")\n\n\n\n\n\n\n\n\nshows that the value “0” heavily influences the IQR of the “Normal” heart disease category. The value “0” has much less effect on the IQR of the “Heart Disease” heart disease category. This suggests that Oldpeak is suitable for inclusion in prediction modeling.\nWe did not analyze ST_Slope because the variable is being dropped from the data set per the Homework5 instructions.\n\n\n\n\nadjusted_heart_df &lt;- adjusted_heart_df |&gt;\n  mutate(HeartDiseaseFct = factor(HeartDisease, levels = c(0, 1), labels = c(\"No\", \"Yes\")), .before = 11) |&gt;\n  select(Age:HeartDiseaseFct)\n\n\n\n\nSet up dummy variables for ExerciseAngina, ChestPainType, and RestingECG using dummyVars() and predict(). Then we will convert the resulting table into a data frame for use in our predictive models.\n\n# Create the dummy variables\ndummies &lt;- dummyVars(~ ., data = adjusted_heart_df)\n\n# Create the new data set. Is initially in a `list` format. \ndummy_df &lt;- predict(dummies, newdata = adjusted_heart_df)\n\n# Convert the list into a tibble for use\nmodeling_df &lt;- as_tibble((dummy_df))\n\n# Output the data frame\nprint(modeling_df)\n\n# A tibble: 910 × 19\n     Age  SexF  SexM ChestPainTypeASY ChestPainTypeATA ChestPainTypeNAP\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1    40     0     1                0                1                0\n 2    49     1     0                0                0                1\n 3    37     0     1                0                1                0\n 4    48     1     0                1                0                0\n 5    54     0     1                0                0                1\n 6    39     0     1                0                0                1\n 7    45     1     0                0                1                0\n 8    54     0     1                0                1                0\n 9    37     0     1                1                0                0\n10    48     1     0                0                1                0\n# ℹ 900 more rows\n# ℹ 13 more variables: ChestPainTypeTA &lt;dbl&gt;, RestingBP &lt;dbl&gt;,\n#   Cholesterol &lt;dbl&gt;, FastingBS &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, MaxHR &lt;dbl&gt;,\n#   ExerciseAnginaN &lt;dbl&gt;, ExerciseAnginaY &lt;dbl&gt;, Oldpeak &lt;dbl&gt;,\n#   HeartDiseaseFct.No &lt;dbl&gt;, HeartDiseaseFct.Yes &lt;dbl&gt;\n\n\n\n\n\n\nNow that we have a data frame with dummy variables for the variables with factor levels, we can split the data into training and test sets for use when developing our prediction models.\nWe previously identified that ChestPainType and RestingECG are not suitable for prediction modeling. Because of this, we will remove them then create our training our test subsets.\n\n# Remove ChestPainType, RestingECG, and HeartDisese.No from the data frame\n\n# HeartDisease.No is being removed because it is the inverse of the variable of\n# HeartDisease.Yes which we are using as the predicted variable. \n\nmodeling_df &lt;- modeling_df |&gt;\n  relocate(starts_with(\"Heart\")) |&gt;\n  select(-HeartDiseaseFct.No) \n  \nmodeling_df\n\n# A tibble: 910 × 18\n   HeartDiseaseFct.Yes   Age  SexF  SexM ChestPainTypeASY ChestPainTypeATA\n                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1                   0    40     0     1                0                1\n 2                   1    49     1     0                0                0\n 3                   0    37     0     1                0                1\n 4                   1    48     1     0                1                0\n 5                   0    54     0     1                0                0\n 6                   0    39     0     1                0                0\n 7                   0    45     1     0                0                1\n 8                   0    54     0     1                0                1\n 9                   1    37     0     1                1                0\n10                   0    48     1     0                0                1\n# ℹ 900 more rows\n# ℹ 12 more variables: ChestPainTypeNAP &lt;dbl&gt;, ChestPainTypeTA &lt;dbl&gt;,\n#   RestingBP &lt;dbl&gt;, Cholesterol &lt;dbl&gt;, FastingBS &lt;dbl&gt;, RestingECGLVH &lt;dbl&gt;,\n#   RestingECGNormal &lt;dbl&gt;, RestingECGST &lt;dbl&gt;, MaxHR &lt;dbl&gt;,\n#   ExerciseAnginaN &lt;dbl&gt;, ExerciseAnginaY &lt;dbl&gt;, Oldpeak &lt;dbl&gt;\n\n\nOur Training and Test data set rows are\n\n# Use set.seed() to ensure the output is reproducible each time the program\n# is used. We will do this for each block of code where the data iterations\n# may change. \n\nset.seed(1) \n\n# Create the model index that will partition the data\nmodelingIndex &lt;- createDataPartition(modeling_df$HeartDiseaseFct.Yes, p = .75, list = FALSE)\n\n# Create the training set by giving it the index row values\nmodelingTrain &lt;- modeling_df[modelingIndex, ]\n\n# Create the test set by givign it the remaining rows\nmodelingTest &lt;- modeling_df[-modelingIndex, ]\n\n# Output the dimensions to ensure the data subsets populated correctly\nprint(list(\"Training Data\" = dim(modelingTrain), \"Testing Data\" = dim(modelingTest)))\n\n$`Training Data`\n[1] 683  18\n\n$`Testing Data`\n[1] 227  18\n\n\nNow that we have created our test and training sets, we will fit them to a knn prediction model.\n\n\n\n\n\nAll of the variables are numeric after creating the data frame with dummy variables for the levels of Sex, ExerciseAngina, and HeartDisease. We previously removed variables ChestPainType and RestingECG due to them not being good for predictive modeling. We are now ready to train and test our prediction models.\nWe will assign the target variable as HeartDisease.Yes, and convert it to a factor in both our training and test sets for use in comparison modeling.\n\nmodelingTrain$HeartDiseaseFct.Yes &lt;- factor(modelingTrain$HeartDiseaseFct.Yes)\n\nmodelingTest$HeartDiseaseFct.Yes &lt;- factor(modelingTest$HeartDiseaseFct.Yes)\n\n\n\n\nWe are using the train() function to generate our fit using the KNN method. Parameters we’re using are 10 fold cross-validation with the number of steps being 3 and tuneGrid set so that the considered values for k are “1” through “40”.\n\nset.seed(1) #ensures reproducibility \n\nknnFit &lt;- train(HeartDiseaseFct.Yes ~ ., \n                data = modelingTrain,\n                method = \"knn\",\n                preProcess = c(\"center\", \"scale\"), \n                trControl = trainControl(method = \"repeatedcv\",\n                                         number = 10, \n                                         repeats = 3),\n                tuneGrid = data.frame(k = 1:40))\n\nprint(knnFit)\n\nk-Nearest Neighbors \n\n683 samples\n 17 predictor\n  2 classes: '0', '1' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 614, 615, 615, 614, 615, 615, ... \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa    \n   1  0.7452592  0.4864624\n   2  0.7442427  0.4859925\n   3  0.7964954  0.5897771\n   4  0.8037848  0.6030912\n   5  0.8140434  0.6246115\n   6  0.8105761  0.6175392\n   7  0.8174745  0.6309950\n   8  0.8155491  0.6272299\n   9  0.8194635  0.6353733\n  10  0.8135670  0.6231668\n  11  0.8169981  0.6304209\n  12  0.8135741  0.6231213\n  13  0.8126286  0.6208704\n  14  0.8107106  0.6165781\n  15  0.8136303  0.6223585\n  16  0.8150516  0.6248249\n  17  0.8146036  0.6240824\n  18  0.8136234  0.6225030\n  19  0.8150942  0.6252484\n  20  0.8131334  0.6211978\n  21  0.8156053  0.6261971\n  22  0.8136587  0.6225243\n  23  0.8121741  0.6188596\n  24  0.8107177  0.6157477\n  25  0.8072864  0.6090371\n  26  0.8072508  0.6088302\n  27  0.8077695  0.6098379\n  28  0.8053185  0.6043274\n  29  0.8077552  0.6092609\n  30  0.8028746  0.5992229\n  31  0.8072937  0.6076927\n  32  0.8058160  0.6048312\n  33  0.8067964  0.6067857\n  34  0.8043667  0.6018587\n  35  0.8063346  0.6055834\n  36  0.8029030  0.5989761\n  37  0.8029243  0.5980254\n  38  0.8029243  0.5979392\n  39  0.8038976  0.5997103\n  40  0.8024412  0.5966529\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 9.\n\n\nThe kNN model identified k = 9 as the most accurate parameter value with a prediction accuracy value of 81.95%.\n\n\n\nNow that we have a model, we will check how well it does using the confusionMatrix function to analyze it against the test set.\n\n# Generate model prediction against the test data set\nknn_pred &lt;- predict(knnFit, newdata = modelingTest)\n\n# Validate the accuracy of the prediction against the test data set \nknn_accuracy &lt;- confusionMatrix(knn_pred, modelingTest$HeartDiseaseFct.Yes)\n\n# Output results\nprint(knn_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0  88  22\n         1  17 100\n                                          \n               Accuracy : 0.8282          \n                 95% CI : (0.7727, 0.8749)\n    No Information Rate : 0.5374          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6556          \n                                          \n Mcnemar's Test P-Value : 0.5218          \n                                          \n            Sensitivity : 0.8381          \n            Specificity : 0.8197          \n         Pos Pred Value : 0.8000          \n         Neg Pred Value : 0.8547          \n             Prevalence : 0.4626          \n         Detection Rate : 0.3877          \n   Detection Prevalence : 0.4846          \n      Balanced Accuracy : 0.8289          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nconfusionMatrix testing showed that our kNN model is approximately 81.06% accurate at predicting if a PT has Heart Disease or not. This accuracy is higher than what our model accuracy generated during training.\n\n\n\n\n\n\nUsing the EDA from section 2.1 we are going to generate regression models using the adjacent categories probability, Bayesian general linear model, and general linear model types.\nFirst, we will need to create training and test sets without our dummy variables and rearrange the data frame to put variables we’re going to remove.\n\nadjusted_heart_df &lt;- adjusted_heart_df |&gt;\n  relocate(HeartDiseaseFct, .before = 1) |&gt;\n  relocate(ChestPainType, .after = Oldpeak) |&gt;\n  relocate(RestingECG, .after = Oldpeak)\n\nset.seed(1) #ensures reproducibility \n\n# Create the index to determine data split\nheart_index &lt;- createDataPartition(adjusted_heart_df$HeartDiseaseFct,\n                                 p = 0.75,\n                                 list = FALSE)\n\n# Create the train data set\nheart_train &lt;- adjusted_heart_df[heart_index, ]\n\n# Crete the test data set\nheart_test &lt;- adjusted_heart_df[-heart_index, ]\n\n# Output the dimensions to ensure the data subsets populated correctly\nprint(list(\"Heart Training Dimensions\" = dim(heart_train), \n           \"Heart Test Dimensions\" = dim(heart_test)))\n\n$`Heart Training Dimensions`\n[1] 684  11\n\n$`Heart Test Dimensions`\n[1] 226  11\n\n\nNow, we will fit the models on the training set using CV with the same parameters used in the kNN model.\nThe first model is based on using ExerciseAngina as a predictor variable. The second model is based on using Oldpeak as a predictor variable. The third model uses all variables in the data frame. ExerciseAngina and Oldpeak are chosen as independent predictors because of the differences between the subgroups of HeartDisease.\n\nset.seed(1) #ensures reproducibility \n\n# Predict using only ExerciseAngina\nmod1 &lt;- train(HeartDiseaseFct ~ ExerciseAngina, \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Predict using ExerciseAngina and Oldpeak\nmod2 &lt;- train(HeartDiseaseFct ~ ExerciseAngina + Oldpeak, \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Predict using all variables\nmod3 &lt;- train(HeartDiseaseFct ~ ., \n              data = heart_train,\n              method = \"glm\", \n              preProcess = c(\"center\", \"scale\"), \n              trControl = trainControl(method = \"repeatedcv\",\n                                       number = 10, \n                                       repeats = 3)\n)\n\n# Create a data frame for use in side-by-side comparison of the results\nprint(data.frame(t(mod1$results), t(mod2$results), t(mod3$results)))\n\n                   X1       X1.1       X1.2\nparameter        none       none       none\nAccuracy    0.7324338  0.7626267  0.8148827\nKappa       0.4749257  0.5249901  0.6249328\nAccuracySD 0.05003336 0.05936164 0.05221871\nKappaSD    0.09532202  0.1175836  0.1056164\n\n\nThe best model of the three is model 3, the full model. ExerciseAngina tested well as an independent predictor with an accuracy rate of 73.24%. Adding Oldpeak only slightly improved the prediction model to an accuracy rate of 76.26% respectively, but were beaten out by the full model accurate rate of 81.77%.\nThe full model doing the best was not unexpected. There are several variables that appeared to influence HeartDisease. What was surprising is adding the remaining variables only increased the accuracy by “5.22%”.\nNow that we have chosen our model, we will check how well it does on the test set using the confusionMatrix function.\n\nset.seed(1) #ensures reproducibility \n\n# Generate model prediction against the test data set\nlr_pred &lt;- predict(mod3, newdata = heart_test)\n\n# Validate the accuracy of the prediction against the test data set\nlr_accuracy &lt;- confusionMatrix(lr_pred, heart_test$HeartDiseaseFct)\n\n# Output results\nprint(lr_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No   82  23\n       Yes  19 102\n                                          \n               Accuracy : 0.8142          \n                 95% CI : (0.7572, 0.8627)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.6255          \n                                          \n Mcnemar's Test P-Value : 0.6434          \n                                          \n            Sensitivity : 0.8119          \n            Specificity : 0.8160          \n         Pos Pred Value : 0.7810          \n         Neg Pred Value : 0.8430          \n             Prevalence : 0.4469          \n         Detection Rate : 0.3628          \n   Detection Prevalence : 0.4646          \n      Balanced Accuracy : 0.8139          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nconfusionMatrix testing showed that our chosen logistic regression model is approximately 81.42% accurate at predicting if a PT has Heart Disease or not.\n\n\n\n\n\n\nThe variables chosen for the following models include the variables not tested previously Age, RestingBP, and MaxHR. These variables appeared to be suitable for predicting HeartDisease during EDA, but were not used in the LR modeling.\nFor consistency, we will be using the same train and test subsets used in performing our logistic regression models. With these subsets, we will generate a classification tree, random forest tree, and a boosted tree using repeated 10 fold CV along with specified parameters in order to select a best fit.\nFor our classification tree, we will be using method - “rpart” and tuning parameter “cp”. We will assign values “0” though “0.1” by “0.001” to “cp”.\n\nheart_train$HeartDiseaseFct &lt;- factor(heart_train$HeartDiseaseFct )\n\nheart_test$HeartDiseaseFct &lt;- factor(heart_test$HeartDiseaseFct)\n\n\nset.seed(1)\n\nrpart_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"rpart\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(cp = seq(0, 0.1, by = 0.001))\n                     )\n\nprint(rpart_train)\n\nCART \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  cp     Accuracy   Kappa    \n  0.000  0.6272165  0.2411720\n  0.001  0.6330563  0.2520685\n  0.002  0.6418159  0.2701780\n  0.003  0.6491049  0.2836107\n  0.004  0.6564152  0.2980856\n  0.005  0.6652387  0.3167001\n  0.006  0.6725916  0.3333849\n  0.007  0.6784740  0.3461025\n  0.008  0.6901108  0.3694299\n  0.009  0.6915601  0.3730399\n  0.010  0.6959292  0.3806008\n  0.011  0.6959506  0.3803255\n  0.012  0.6959506  0.3803255\n  0.013  0.6959506  0.3812563\n  0.014  0.6959506  0.3812563\n  0.015  0.6974211  0.3824056\n  0.016  0.6974211  0.3824056\n  0.017  0.7003623  0.3881406\n  0.018  0.7003623  0.3881406\n  0.019  0.6959506  0.3801877\n  0.020  0.6959506  0.3801877\n  0.021  0.6959506  0.3801877\n  0.022  0.6959506  0.3801877\n  0.023  0.6959506  0.3801877\n  0.024  0.6885976  0.3639843\n  0.025  0.6885976  0.3639843\n  0.026  0.6885976  0.3639843\n  0.027  0.6885976  0.3639843\n  0.028  0.6885976  0.3639843\n  0.029  0.6885976  0.3639843\n  0.030  0.6885976  0.3639843\n  0.031  0.6885976  0.3639843\n  0.032  0.6885976  0.3639843\n  0.033  0.6885976  0.3639843\n  0.034  0.6885976  0.3639843\n  0.035  0.6885976  0.3639843\n  0.036  0.6885976  0.3639843\n  0.037  0.6783035  0.3410922\n  0.038  0.6783035  0.3410922\n  0.039  0.6783035  0.3410922\n  0.040  0.6783035  0.3410922\n  0.041  0.6783035  0.3410922\n  0.042  0.6783035  0.3410922\n  0.043  0.6783035  0.3410922\n  0.044  0.6783035  0.3387667\n  0.045  0.6783035  0.3387667\n  0.046  0.6783035  0.3387667\n  0.047  0.6783035  0.3387667\n  0.048  0.6783035  0.3387667\n  0.049  0.6783035  0.3387667\n  0.050  0.6783035  0.3387667\n  0.051  0.6783035  0.3387667\n  0.052  0.6783035  0.3387667\n  0.053  0.6783035  0.3387667\n  0.054  0.6783035  0.3387667\n  0.055  0.6783035  0.3387667\n  0.056  0.6783035  0.3387667\n  0.057  0.6783035  0.3387667\n  0.058  0.6783035  0.3387667\n  0.059  0.6783035  0.3387667\n  0.060  0.6783035  0.3387667\n  0.061  0.6783035  0.3387667\n  0.062  0.6783035  0.3387667\n  0.063  0.6783035  0.3387667\n  0.064  0.6783035  0.3387667\n  0.065  0.6783035  0.3387667\n  0.066  0.6783035  0.3387667\n  0.067  0.6783035  0.3387667\n  0.068  0.6783035  0.3387667\n  0.069  0.6783035  0.3387667\n  0.070  0.6783035  0.3387667\n  0.071  0.6783035  0.3387667\n  0.072  0.6783035  0.3387667\n  0.073  0.6783035  0.3387667\n  0.074  0.6783035  0.3387667\n  0.075  0.6783035  0.3387667\n  0.076  0.6783035  0.3387667\n  0.077  0.6783035  0.3387667\n  0.078  0.6783035  0.3387667\n  0.079  0.6783035  0.3387667\n  0.080  0.6783035  0.3387667\n  0.081  0.6783035  0.3387667\n  0.082  0.6783035  0.3387667\n  0.083  0.6783035  0.3387667\n  0.084  0.6637042  0.3155123\n  0.085  0.6637042  0.3155123\n  0.086  0.6637042  0.3155123\n  0.087  0.6637042  0.3155123\n  0.088  0.6637042  0.3155123\n  0.089  0.6637042  0.3155123\n  0.090  0.6637042  0.3155123\n  0.091  0.6534314  0.3017520\n  0.092  0.6534314  0.3017520\n  0.093  0.6534314  0.3017520\n  0.094  0.6534314  0.3017520\n  0.095  0.6446078  0.2869951\n  0.096  0.6446078  0.2869951\n  0.097  0.6446078  0.2869951\n  0.098  0.6446078  0.2869951\n  0.099  0.6446078  0.2869951\n  0.100  0.6446078  0.2869951\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was cp = 0.018.\n\n\nThe optimal model using “rpart” had a cp = 0.03 with a prediction accuracy of 65.50%\nFor our random forest tree model, we will be using method = “rf” with mtry as the tuning parameter with the number of predictors for it’s value.\n\nset.seed(1)\n\nrf_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"rf\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(mtry = c(1, 2, 3))\n                     )\n\nprint(rf_train)\n\nRandom Forest \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  mtry  Accuracy   Kappa    \n  1     0.6651321  0.3192079\n  2     0.6401748  0.2702785\n  3     0.6285166  0.2471447\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was mtry = 1.\n\n\nThe optimal model using “rf” was mtry = 1 with a prediction accuracy of 66.68%\nFor our boosted tree model, we will be using method = “gbm” with n.trees, interaction.depth, shrinkage, and n.minobsinnode.\n\nset.seed(1)\n\ngbm_train &lt;- train(HeartDiseaseFct ~ Age + RestingBP + MaxHR, \n                     data = heart_train, \n                     method = \"gbm\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     verbose = FALSE, \n                     tuneGrid = expand.grid(n.trees = c(25, 50, 100, 200),\n                       interaction.depth = c(1, 2, 3), \n                       shrinkage = 0.1,\n                       n.minobsinnode = 10\n                       )\n                     )\n\nprint(gbm_train)\n\nStochastic Gradient Boosting \n\n684 samples\n  3 predictor\n  2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 1 times) \nSummary of sample sizes: 616, 615, 616, 615, 616, 616, ... \nResampling results across tuning parameters:\n\n  interaction.depth  n.trees  Accuracy   Kappa    \n  1                   25      0.6945013  0.3758984\n  1                   50      0.6974851  0.3823038\n  1                  100      0.6959506  0.3806259\n  1                  200      0.6901748  0.3688129\n  2                   25      0.6886189  0.3642760\n  2                   50      0.6900682  0.3671151\n  2                  100      0.6842072  0.3549362\n  2                  200      0.6840793  0.3580468\n  3                   25      0.7046462  0.3987894\n  3                   50      0.6959079  0.3809876\n  3                  100      0.6841006  0.3554644\n  3                  200      0.6739770  0.3359869\n\nTuning parameter 'shrinkage' was held constant at a value of 0.1\n\nTuning parameter 'n.minobsinnode' was held constant at a value of 10\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were n.trees = 25, interaction.depth =\n 3, shrinkage = 0.1 and n.minobsinnode = 10.\n\n\nThe optimal model using “gbm” was the combination of n.trees = 25, interaction.depth = 3, shrinkage = 0.1, and n.minobsinnode = 10 with a prediction accuracy of 70.48%\nCheck how each of the above chosen models do on the test set using the confusionMatrix function.\n\nset.seed(1)\n\n# Generate model predictions against the test data set\nrpart_train_pred &lt;- predict(rpart_train, newdata = heart_test)\n#rf_train_pred &lt;- predict(rf_train, newdata = heart_test)\n#gbm_train_pred &lt;- predict(boosted_train, newdata = heart_test)\n\n\n# Validate the accuracy of the prediction against the test data set\nrpart_accuracy &lt;- confusionMatrix(rpart_train_pred, heart_test$HeartDiseaseFct)\n#rf_accuracy &lt;- confusionMatrix(rf_train_pred, heart_test$HeartDiseaseFct)\n#gbm_accuracy &lt;- confusionMatrix(gbm_train_pred, heart_test$HeartDiseaseFct)\n\n\n# Frame the results for comparison\n#regTrees &lt;- data.frame(rpart_accuracy$overall, rf_accuracy$overall, boosted_accuracy$overall)\n\n# Output the results\n#print(regTrees)\n\nprint(rpart_accuracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No   64  23\n       Yes  37 102\n                                          \n               Accuracy : 0.7345          \n                 95% CI : (0.6719, 0.7909)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : 1.403e-08       \n                                          \n                  Kappa : 0.4557          \n                                          \n Mcnemar's Test P-Value : 0.09329         \n                                          \n            Sensitivity : 0.6337          \n            Specificity : 0.8160          \n         Pos Pred Value : 0.7356          \n         Neg Pred Value : 0.7338          \n             Prevalence : 0.4469          \n         Detection Rate : 0.2832          \n   Detection Prevalence : 0.3850          \n      Balanced Accuracy : 0.7248          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nComparing our three regression tree models after processing them through the confusionMatrix function shows that the rpart regression tree method had the highest level of accuracy at 73.45%, closely followed by the “gbm” regression tree method with an accuracy level of 71.68%.\n\n\n\n\n\n\nWhen doing a side by side comparison of the confusionMatrix generated accuracy rates of the three selected model types,\n\nmodel &lt;- c(\"kNN\", \"LogRegression\", \"Tree\")\n\naccuracy &lt;- c(0.8282, 0.8142, 0.7345)\n\ncomparison &lt;- data.frame(model, accuracy)\n\nprint(list(\"Comparison of Prediction Models\" = comparison))\n\n$`Comparison of Prediction Models`\n          model accuracy\n1           kNN   0.8282\n2 LogRegression   0.8142\n3          Tree   0.7345\n\n\nwe found that the k-Nearest Neighbors model was the most accurate, closely followed by the Logistic Regression model. However, the tree models were not tested using the same variables as the kNN and Logistic Regression models. A true comparison of the models would require our selected tree model to train and test on every variable for prediction like the other models.\n\nset.seed(1) #ensures reproducibility \n\nrpart_train2 &lt;- train(HeartDiseaseFct ~ ., \n                     data = heart_train, \n                     method = \"rpart\", \n                     trControl = trainControl(method = \"repeatedcv\",\n                                              number = 10),\n                     tuneGrid = data.frame(cp = seq(0, 0.1, by = 0.001))\n                     )\n\nrpart_train_pred2 &lt;- predict(rpart_train2, newdata = heart_test)\n\nrpart_accuracy2 &lt;- confusionMatrix(rpart_train_pred2, heart_test$HeartDiseaseFct)\n\nprint(rpart_accuracy2)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  84  26\n       Yes 17  99\n                                          \n               Accuracy : 0.8097          \n                 95% CI : (0.7524, 0.8587)\n    No Information Rate : 0.5531          \n    P-Value [Acc &gt; NIR] : 4.247e-16       \n                                          \n                  Kappa : 0.6184          \n                                          \n Mcnemar's Test P-Value : 0.2225          \n                                          \n            Sensitivity : 0.8317          \n            Specificity : 0.7920          \n         Pos Pred Value : 0.7636          \n         Neg Pred Value : 0.8534          \n             Prevalence : 0.4469          \n         Detection Rate : 0.3717          \n   Detection Prevalence : 0.4867          \n      Balanced Accuracy : 0.8118          \n                                          \n       'Positive' Class : No              \n                                          \n\n\nThe new matrix for comparison of model accuracy shows\n\nmodel &lt;- c(\"kNN\", \"LogRegression\", \"Tree\")\n\naccuracy &lt;- c(0.8282, 0.8142, 0.8097)\n\ncomparison &lt;- data.frame(model, accuracy)\n\nprint(list(\"Comparison of Prediction Models\" = comparison))\n\n$`Comparison of Prediction Models`\n          model accuracy\n1           kNN   0.8282\n2 LogRegression   0.8142\n3          Tree   0.8097\n\n\nthat there is no change in the accuracy rankings, but the Tree model’s accuracy had vastly improved by including the variables that were previously omitted."
  }
]